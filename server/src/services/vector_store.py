"""
Servi√ßo de banco vetorial usando ChromaDB.
Implementa a funcionalidade RAG (Retrieval-Augmented Generation) para contextualizar
a gera√ß√£o de conte√∫do com base na base de conhecimento do usu√°rio.
"""

import chromadb
from chromadb.config import Settings
from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction
import uuid
from typing import List, Dict, Any, Optional, Tuple
import logging
from pathlib import Path

from ..core.config import settings

logger = logging.getLogger(__name__)

class VectorStoreService:
    """
    Servi√ßo para gerenciar o banco vetorial ChromaDB

    Respons√°vel por:
    - Armazenar embeddings de documentos
    - Buscar conte√∫do relevante por similaridade
    - Gerenciar cole√ß√µes por persona
    - Otimizar recupera√ß√£o de contexto para RAG
    """

    def __init__(self):
        self.client = None
        self.collections = {}
        self.embedding_function = None

    async def initialize(self):
        """Inicializa o cliente ChromaDB"""
        try:
            # Configurar ChromaDB
            chroma_settings = Settings(
                persist_directory=str(settings.chroma_path),
                anonymized_telemetry=False
            )

            # Criar cliente persistente
            self.client = chromadb.PersistentClient(
                path=str(settings.chroma_path),
                settings=chroma_settings
            )

            # Configurar fun√ß√£o de embedding (Sentence Transformers local)
            # Usa um modelo leve e gratuito por padr√£o, evitando custos por requisi√ß√£o
            # Modelos poss√≠veis: 'all-MiniLM-L6-v2' (r√°pido) ou 'multi-qa-MiniLM-L6-cos-v1'
            self.embedding_function = SentenceTransformerEmbeddingFunction(
                model_name="all-MiniLM-L6-v2"
            )

            logger.info(f"‚úÖ ChromaDB inicializado em: {settings.chroma_path}")

        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar ChromaDB: {e}")
            raise

    def get_collection_name(self, persona_id: int) -> str:
        """Gera nome da cole√ß√£o para uma persona espec√≠fica"""
        return f"persona_{persona_id}_knowledge"

    async def get_or_create_collection(self, persona_id: int):
        """Obt√©m ou cria uma cole√ß√£o para uma persona"""
        collection_name = self.get_collection_name(persona_id)

        if collection_name not in self.collections:
            try:
                # Tentar obter/criar cole√ß√£o garantindo fun√ß√£o de embedding configurada
                collection = self.client.get_or_create_collection(
                    name=collection_name,
                    embedding_function=self.embedding_function,
                    metadata={"persona_id": persona_id}
                )
                logger.info(f"üìö Cole√ß√£o pronta: {collection_name}")
            except Exception as e:
                logger.error(f"‚ùå Erro ao obter/criar cole√ß√£o {collection_name}: {e}")
                raise

            self.collections[collection_name] = collection

        return self.collections[collection_name]

    async def add_document(
        self,
        persona_id: int,
        document_id: str,
        text_chunks: List[str],
        metadata: Dict[str, Any]
    ) -> bool:
        """
        Adiciona um documento ao banco vetorial

        Args:
            persona_id: ID da persona
            document_id: ID √∫nico do documento
            text_chunks: Lista de chunks de texto
            metadata: Metadados do documento

        Returns:
            bool: True se adicionado com sucesso
        """
        try:
            collection = await self.get_or_create_collection(persona_id)

            # Preparar dados para inser√ß√£o
            documents = text_chunks
            metadatas = []
            ids = []

            for i, chunk in enumerate(text_chunks):
                chunk_id = f"{document_id}_chunk_{i}"
                chunk_metadata = {
                    **metadata,
                    "chunk_index": i,
                    "document_id": document_id,
                    "chunk_id": chunk_id
                }

                ids.append(chunk_id)
                metadatas.append(chunk_metadata)

            # Adicionar ao ChromaDB
            collection.add(
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )

            logger.info(f"‚úÖ Documento {document_id} adicionado com {len(text_chunks)} chunks")
            return True

        except Exception as e:
            logger.error(f"‚ùå Erro ao adicionar documento {document_id}: {e}")
            return False

    async def search_similar_content(
        self,
        persona_id: int,
        query: str,
        n_results: int = None,
        filter_metadata: Dict[str, Any] = None
    ) -> List[Dict[str, Any]]:
        """
        Busca conte√∫do similar no banco vetorial

        Args:
            persona_id: ID da persona
            query: Texto de busca
            n_results: N√∫mero de resultados (padr√£o: configura√ß√£o)
            filter_metadata: Filtros de metadados

        Returns:
            List[Dict]: Lista de documentos similares com metadados
        """
        try:
            collection = await self.get_or_create_collection(persona_id)

            if n_results is None:
                n_results = settings.TOP_K_RETRIEVAL

            # Executar busca por similaridade
            results = collection.query(
                query_texts=[query],
                n_results=n_results,
                where=filter_metadata
            )

            # Formatar resultados
            similar_docs = []
            if results['documents'] and results['documents'][0]:
                for i, doc in enumerate(results['documents'][0]):
                    similar_docs.append({
                        'content': doc,
                        'metadata': results['metadatas'][0][i] if results['metadatas'] else {},
                        'distance': results['distances'][0][i] if results['distances'] else 0.0,
                        'id': results['ids'][0][i] if results['ids'] else None
                    })

            logger.info(f"üîç Encontrados {len(similar_docs)} documentos similares para persona {persona_id}")
            return similar_docs

        except Exception as e:
            logger.error(f"‚ùå Erro na busca de similaridade: {e}")
            return []

    async def delete_document(self, persona_id: int, document_id: str) -> bool:
        """
        Remove um documento do banco vetorial

        Args:
            persona_id: ID da persona
            document_id: ID do documento

        Returns:
            bool: True se removido com sucesso
        """
        try:
            collection = await self.get_or_create_collection(persona_id)

            # Buscar todos os chunks do documento
            results = collection.get(
                where={"document_id": document_id}
            )

            if results['ids']:
                # Deletar todos os chunks
                collection.delete(ids=results['ids'])
                logger.info(f"üóëÔ∏è Documento {document_id} removido ({len(results['ids'])} chunks)")
                return True
            else:
                logger.warning(f"‚ö†Ô∏è Documento {document_id} n√£o encontrado")
                return False

        except Exception as e:
            logger.error(f"‚ùå Erro ao deletar documento {document_id}: {e}")
            return False

    async def get_collection_stats(self, persona_id: int) -> Dict[str, Any]:
        """
        Obt√©m estat√≠sticas da cole√ß√£o de uma persona

        Returns:
            Dict: Estat√≠sticas da cole√ß√£o
        """
        try:
            collection = await self.get_or_create_collection(persona_id)

            # Obter contagem de documentos
            count_result = collection.count()

            # Obter alguns metadados para an√°lise
            sample_results = collection.get(limit=10)

            # Calcular estat√≠sticas
            unique_documents = set()
            if sample_results.get('metadatas'):
                for metadata in sample_results['metadatas']:
                    if 'document_id' in metadata:
                        unique_documents.add(metadata['document_id'])

            stats = {
                'total_chunks': count_result,
                'estimated_documents': len(unique_documents),
                'collection_name': self.get_collection_name(persona_id),
                'persona_id': persona_id
            }

            return stats

        except Exception as e:
            logger.error(f"‚ùå Erro ao obter estat√≠sticas: {e}")
            return {'error': str(e)}

    async def clear_persona_collection(self, persona_id: int) -> bool:
        """
        Limpa todos os documentos de uma persona

        Args:
            persona_id: ID da persona

        Returns:
            bool: True se limpo com sucesso
        """
        try:
            collection_name = self.get_collection_name(persona_id)

            # Deletar cole√ß√£o
            self.client.delete_collection(collection_name)

            # Remover do cache
            if collection_name in self.collections:
                del self.collections[collection_name]

            logger.info(f"üßπ Cole√ß√£o da persona {persona_id} limpa")
            return True

        except Exception as e:
            logger.error(f"‚ùå Erro ao limpar cole√ß√£o: {e}")
            return False

# Inst√¢ncia global
vector_store = VectorStoreService()

async def init_vector_store():
    """Inicializa o servi√ßo de banco vetorial"""
    await vector_store.initialize()